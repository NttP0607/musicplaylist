import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# --- C·∫§U H√åNH GI·∫¢ ƒê·ªäNH ---
# THAY TH·∫æ C√ÅC GI√Å TR·ªä N√ÄY V·ªöI TH√îNG TIN T·ª™ CONFIG C·ª¶A B·∫†N!
MODEL_PATH = "D:/PBL6/musicapppr_full/musicapppr_backend/AI/text_emotion_model"  # ƒê∆∞·ªùng d·∫´n t·ªõi th∆∞ m·ª•c m√¥ h√¨nh
MAX_LENGTH = 128                     # Chi·ªÅu d√†i t·ªëi ƒëa c·ªßa chu·ªói
# L∆∞u √Ω: C·∫ßn ki·ªÉm tra th·ª© t·ª± nh√£n ch√≠nh x√°c trong config.json c·ªßa m√¥ h√¨nh b·∫°n.
EMOTION_LABELS = ["sadness", "joy", "love", "anger", "fear"] 

# --- 1. T·∫£i M√¥ h√¨nh v√† Tokenizer (Ch·ªâ m·ªôt l·∫ßn) ---
def load_model_and_tokenizer(model_path, max_length):
    """T·∫£i m√¥ h√¨nh v√† tokenizer v√† in ra c·∫•u h√¨nh nh√£n."""
    try:
        tokenizer = AutoTokenizer.from_pretrained(model_path)
        model = AutoModelForSequenceClassification.from_pretrained(model_path)
        model.eval() # ƒê·∫∑t m√¥ h√¨nh ·ªü ch·∫ø ƒë·ªô ƒë√°nh gi√°
        print(f"‚úÖ ƒê√£ t·∫£i m√¥ h√¨nh t·ª´ '{model_path}' th√†nh c√¥ng.")
        
        # In nh√£n ra m√†n h√¨nh ƒë·ªÉ ng∆∞·ªùi d√πng ki·ªÉm tra
        print(f"Nh√£n c·∫£m x√∫c ƒë∆∞·ª£c s·ª≠ d·ª•ng (theo th·ª© t·ª± ID): {EMOTION_LABELS}")
        
        return tokenizer, model
    except Exception as e:
        print(f"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh t·ª´ ƒë∆∞·ªùng d·∫´n: {model_path}. L·ªói: {e}")
        return None, None

# --- 2. H√†m D·ª± ƒëo√°n C·∫£m x√∫c ---
def infer_text_emotion(text, tokenizer, model, max_length):
    """
    Infer the emotion from the given text using the trained text emotion model.

    :param text: VƒÉn b·∫£n ƒë·∫ßu v√†o.
    :param tokenizer: ƒê·ªëi t∆∞·ª£ng tokenizer ƒë√£ t·∫£i.
    :param model: ƒê·ªëi t∆∞·ª£ng model ƒë√£ t·∫£i.
    :param max_length: Chi·ªÅu d√†i t·ªëi ƒëa.
    :return: C·∫£m x√∫c ƒë∆∞·ª£c ph√°t hi·ªán.
    """
    if not model or not tokenizer:
        return "L·ªói: M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng."

    try:
        inputs = tokenizer(
            text, 
            return_tensors="pt", 
            padding=True, 
            truncation=True, 
            max_length=max_length
        )

        with torch.no_grad():
            outputs = model(**inputs)

        # L·∫•y k·∫øt qu·∫£ t·ª´ logits v√† chuy·ªÉn th√†nh numpy
        scores = outputs.logits[0].numpy()
        emotion_idx = scores.argmax()

        # √Ånh x·∫° ch·ªâ s·ªë (index) th√†nh nh√£n (label)
        if emotion_idx < len(EMOTION_LABELS):
            return EMOTION_LABELS[emotion_idx]
        else:
            return f"L·ªói: Ch·ªâ s·ªë c·∫£m x√∫c ({emotion_idx}) n·∫±m ngo√†i ph·∫°m vi nh√£n."
            
    except Exception as e:
        return f"L·ªói trong qu√° tr√¨nh d·ª± ƒëo√°n: {e}"

# --- 3. Ch∆∞∆°ng tr√¨nh Ch√≠nh: Nh·∫≠p t·ª´ B√†n ph√≠m ---
if __name__ == "__main__":
    tokenizer, model = load_model_and_tokenizer(MODEL_PATH, MAX_LENGTH)
    
    if tokenizer and model:
        print("\n--- S·∫µn s√†ng D·ª± ƒëo√°n C·∫£m x√∫c ---")
        print("Nh·∫≠p 'exit' ho·∫∑c 'thoat' ƒë·ªÉ k·∫øt th√∫c.")
        
        while True:
            # Nh·∫≠p vƒÉn b·∫£n t·ª´ b√†n ph√≠m
            input_text = input("\nNh·∫≠p vƒÉn b·∫£n c·ªßa b·∫°n: ")
            
            # Ki·ªÉm tra l·ªánh tho√°t
            if input_text.lower() in ['exit', 'thoat']:
                print("üëã K·∫øt th√∫c ch∆∞∆°ng tr√¨nh.")
                break
            
            if input_text.strip():
                # D·ª± ƒëo√°n c·∫£m x√∫c
                result = infer_text_emotion(input_text, tokenizer, model, MAX_LENGTH)
                
                # Hi·ªÉn th·ªã k·∫øt qu·∫£
                print(f"‚û°Ô∏è **C·∫£m x√∫c D·ª± ƒëo√°n:** **{result.upper()}**")
            else:
                print("VƒÉn b·∫£n kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng.")